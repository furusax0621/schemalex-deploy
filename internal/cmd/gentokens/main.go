package main

import (
	"bytes"
	"flag"
	"fmt"
	"go/format"
	"log"
	"os"
	"strconv"
)

var (
	packageName = flag.String("package", "schemalex", "name of package")
	fileName    = flag.String("file", "tokens_gen.go", "name of file")
)

func main() {
	flag.Parse()
	if err := _main(); err != nil {
		log.Fatal(err)
	}
}

func _main() error {
	var buf bytes.Buffer

	println := func(args ...string) {
		for _, s := range args {
			buf.WriteString(s)
			buf.WriteByte('\n')
		}
	}

	println(
		"// Code generated by internal/cmd/gentokens/main.go; DO NOT EDIT.",
		"",
		"package "+*packageName,
		"",
		"// TokenType describes the possible types of tokens that schemalex understands",
		"type TokenType int",
		"",
		"// Token represents a token",
		"type Token struct {",
		"Type TokenType",
		"Value string",
		"Pos int",
		"Line int",
		"Col int",
		"EOF bool",
		"}",
		"",
	)

	println(
		"// NewToken creates a new token of type `t`, with value `v`",
		"func NewToken(t TokenType, v string) *Token {",
		"return &Token{Type: t, Value: v}",
		"}",
		"",
		"// List of possible tokens",
		"const (",
		"ILLEGAL TokenType = iota",
	)

	tokens := []struct {
		Comment string
		Ident   string
	}{
		{Ident: "EOF"},
		{Ident: "SPACE"},
		{Ident: "IDENT"},
		{Ident: "BACKTICK_IDENT"},
		{Ident: "DOUBLE_QUOTE_IDENT"},
		{Ident: "SINGLE_QUOTE_IDENT"},
		{Ident: "NUMBER"},
		{Ident: "LPAREN", Comment: "("},
		{Ident: "RPAREN", Comment: ")"},
		{Ident: "COMMA", Comment: ","},
		{Ident: "SEMICOLON", Comment: ";"},
		{Ident: "DOT", Comment: "."},
		{Ident: "SLASH", Comment: "/"},
		{Ident: "ASTERISK", Comment: "*"},
		{Ident: "DASH", Comment: "-"},
		{Ident: "PLUS", Comment: "+"},
		{Ident: "SINGLE_QUOTE", Comment: "'"},
		{Ident: "DOUBLE_QUOTE", Comment: "\""},
		{Ident: "EQUAL", Comment: "="},
		{Ident: "COMMENT_IDENT", Comment: `// /*   */, --, #`},
		{Ident: "ACTION"},
		{Ident: "AUTO_INCREMENT"},
		{Ident: "AVG_ROW_LENGTH"},
		{Ident: "BIGINT"},
		{Ident: "BINARY"},
		{Ident: "BIT"},
		{Ident: "BLOB"},
		{Ident: "BOOL"},
		{Ident: "BOOLEAN"},
		{Ident: "BTREE"},
		{Ident: "CASCADE"},
		{Ident: "CHAR"},
		{Ident: "CHARACTER"},
		{Ident: "CHARSET"},
		{Ident: "CHECK"},
		{Ident: "CHECKSUM"},
		{Ident: "COLLATE"},
		{Ident: "COMMENT"},
		{Ident: "COMPACT"},
		{Ident: "COMPRESSED"},
		{Ident: "CONNECTION"},
		{Ident: "CONSTRAINT"},
		{Ident: "CREATE"},
		{Ident: "CURRENT_TIMESTAMP"},
		{Ident: "DATA"},
		{Ident: "DATABASE"},
		{Ident: "DATE"},
		{Ident: "DATETIME"},
		{Ident: "DECIMAL"},
		{Ident: "DEFAULT"},
		{Ident: "DELAY_KEY_WRITE"},
		{Ident: "DELETE"},
		{Ident: "DIRECTORY"},
		{Ident: "DISK"},
		{Ident: "DOUBLE"},
		{Ident: "DROP"},
		{Ident: "DYNAMIC"},
		{Ident: "ENGINE"},
		{Ident: "ENUM"},
		{Ident: "EXISTS"},
		{Ident: "FALSE"},
		{Ident: "FIRST"},
		{Ident: "FIXED"},
		{Ident: "FLOAT"},
		{Ident: "FOREIGN"},
		{Ident: "FULL"},
		{Ident: "FULLTEXT"},
		{Ident: "GEOMETRY"},
		{Ident: "HASH"},
		{Ident: "IF"},
		{Ident: "INDEX"},
		{Ident: "INSERT_METHOD"},
		{Ident: "INT"},
		{Ident: "INTEGER"},
		{Ident: "JSON"},
		{Ident: "KEY"},
		{Ident: "KEY_BLOCK_SIZE"},
		{Ident: "LAST"},
		{Ident: "LIKE"},
		{Ident: "LONGBLOB"},
		{Ident: "LONGTEXT"},
		{Ident: "MATCH"},
		{Ident: "MAX_ROWS"},
		{Ident: "MEDIUMBLOB"},
		{Ident: "MEDIUMINT"},
		{Ident: "MEDIUMTEXT"},
		{Ident: "MEMORY"},
		{Ident: "MIN_ROWS"},
		{Ident: "NO"},
		{Ident: "NOT"},
		{Ident: "NULL"},
		{Ident: "NUMERIC"},
		{Ident: "ON"},
		{Ident: "PACK_KEYS"},
		{Ident: "PARTIAL"},
		{Ident: "PARSER"},
		{Ident: "PASSWORD"},
		{Ident: "PRIMARY"},
		{Ident: "REAL"},
		{Ident: "REDUNDANT"},
		{Ident: "REFERENCES"},
		{Ident: "RESTRICT"},
		{Ident: "ROW_FORMAT"},
		{Ident: "SET"},
		{Ident: "SIMPLE"},
		{Ident: "SMALLINT"},
		{Ident: "SPATIAL"},
		{Ident: "STATS_AUTO_RECALC"},
		{Ident: "STATS_PERSISTENT"},
		{Ident: "STATS_SAMPLE_PAGES"},
		{Ident: "STORAGE"},
		{Ident: "TABLE"},
		{Ident: "TABLESPACE"},
		{Ident: "TEMPORARY"},
		{Ident: "TEXT"},
		{Ident: "TIME"},
		{Ident: "TIMESTAMP"},
		{Ident: "TINYBLOB"},
		{Ident: "TINYINT"},
		{Ident: "TINYTEXT"},
		{Ident: "TRUE"},
		{Ident: "UNION"},
		{Ident: "UNIQUE"},
		{Ident: "UNSIGNED"},
		{Ident: "UPDATE"},
		{Ident: "USE"},
		{Ident: "USING"},
		{Ident: "VARBINARY"},
		{Ident: "VARCHAR"},
		{Ident: "YEAR"},
		{Ident: "WITH"},
		{Ident: "ZEROFILL"},
		{Ident: "ASC"},
		{Ident: "DESC"},
		{Ident: "NOW"},
	}

	for _, tok := range tokens {
		buf.WriteString(tok.Ident)
		if c := tok.Comment; c != "" {
			buf.WriteString("// " + c)
		}
		println("")
	}
	println(")", "") // end const (

	println("var keywordIdentMap = map[string]TokenType{")
	for _, tok := range tokens[20:] {
		println(strconv.Quote(tok.Ident) + ": " + tok.Ident + ",")
	}
	println("}", "")

	println(
		"func (t TokenType) String() string {",
		"switch t {",
		"case ILLEGAL:",
		`return "ILLEGAL"`,
	)
	for _, tok := range tokens {
		println(
			"case "+tok.Ident+":",
			"return "+strconv.Quote(tok.Ident),
		)
	}
	println(
		"}",
		`return "(invalid)"`,
		"}",
	)

	formatted, err := format.Source(buf.Bytes())
	if err != nil {
		fmt.Fprint(os.Stderr, buf.String())
		return err
	}

	return os.WriteFile(*fileName, formatted, 0644)
}
